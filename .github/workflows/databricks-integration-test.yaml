name: Run Integration Tests in Databricks Workflows

on:
  workflow_dispatch:
  pull_request:
    branches:
      - "development"
      - "main"

jobs:
  update_databricks_job_and_run_unit_and_integration_tests:
    runs-on: ubuntu-latest
    env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_PAT }}
    steps:
      - name: Check out code
        uses: actions/checkout@v3

      - name: install-databricks-cli
        uses: databricks/setup-cli@main

      - name: update Databricks Job
        
        run: |
          echo "BRANCH_NAME=${{ github.ref_name }}" >> $GITHUB_ENV
          echo "REPO_URL=${{ vars.REPO_URL }}" >> $GITHUB_ENV
          echo "INTEGRATION_TEST_JOB_ID=${{ vars.INTEGRATION_TEST_JOB_ID }}" >> $GITHUB_ENV
          echo "COMMIT_SHA=${{ github.sha }}" >> $GITHUB_ENV
          echo "GIT_PROVIDER=github" >> $GITHUB_ENV
          echo "EXISTING_CLUSTER_ID=${{ vars.DATABRICKS_EXISTING_CLUSTER_ID }}" >> $GITHUB_ENV
          echo "DATABRICKS_DEV_REPO_NAME=${{ vars.DATABRICKS_DEV_REPO_NAME }}" >> $GITHUB_ENV

      - name: Prepare Tasks
        run: |
            tasks=()
            for notebook in tests/integration/*; do
              notebook_path="tests/integration/$(basename -s .py $notebook)"
              task_key="integration_test_$(basename -s .py $notebook)"
              tasks+=("{\"notebook_task\": {\"notebook_path\": \"$notebook_path\"}, \"task_key\": \"$task_key\", \"existing_cluster_id\": \"$EXISTING_CLUSTER_ID\"}")
            done
            echo "TASKS_STRING=$(IFS=','; echo "${tasks[*]}")" >> $GITHUB_ENV

      - name: Reset Job
        run: |
            job_reset_json="{\"job_id\": $INTEGRATION_TEST_JOB_ID, \"new_settings\": {\"name\": \"Integration Tests\", \"tasks\": [$TASKS_STRING], \"git_source\": {\"git_provider\" : \"$GIT_PROVIDER\", \"git_url\": \"$REPO_URL\", \"git_commit\": \"$COMMIT_SHA\"}}}"
            databricks jobs reset --json "$job_reset_json"

      - name: Run Integration Tests
        run: | 
            databricks jobs run-now $INTEGRATION_TEST_JOB_ID